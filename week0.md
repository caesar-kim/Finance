# 0주차
# 1부. 프레임워크
## 1장. 금융 머신러닝
 - 금융에서의 머신러닝 활용
   - 1 알고리즘 트레이딩
   - 2 포트폴리오 관리 및 로보어드바이저
   - 3 이상 거래 탐지
   - 4 대출/신용카드/보험 계약 심사 (계약심사: underwriting)
   - 5 자동화와 챗봇
   - 6 위험 관리
   - 7 자산 가치 예측
   - 8 파생 상품 가격 책정
   - 9 감정 분석
   - 10 거래 결제
   - 11 돈세탁 방지
- 머신러닝의 유형
  - 지도학습(과제 기반), 비지도학습(데이터 기반), 강화학습(실수로부터의 학습)
    - 지도학습: 회귀호, 분류
    - 비지도학습: 차원축소, 군집화
    - 강화학습: 강화학습에는 분명한 답은 없음. 학습 시스템(에이전트)가 무엇을 할지 결정. 알고리즘이 경험을 통해 답을 결정한다.
    - 자연어 처리
## 2장. 머신러닝 모델 개발

  - 머신러닝에서 파이썬이 가장 지배적인 프로그래밍 언어.
  - 머신러닝에서 주로 사용하는 파이썬 패키지
    - 데이터 표현: NumPy, Pandas
    - 머신러닝, 통계분석: SciPy, Scikit-learn, StatsModels, Keras, Theano, TensorFlow
    - 데이터 시각화: Matplotlib, Seaborn
    - 패키지 관리: pip, Conda
      - 이 중 사이킷런과 케라스가 핵심 패키지. 
- 모델 개발 단계
  - 1 문제 정의 -> 2 데이터&패키지 불러오기 -> 3 탐색적 데이터 분석 ->
  - 4 데이터 준비 -> 5 모델 평가 -> 6 모델 튜닝 및 개선 -> 7 모델 결정
## 3장. 인공신경망
- 인공신경망ANN artificial neural networks
  - 딥러닝은 복잡한 인공신경망 알고리즘을 다룬다.
  - 복잡도는 모델 전체에서 정보 흐름을 나타내는 정교한 패턴에 좌우됨.
  - 딥러닝은 모종의 세계를 개념이 층층이 쌓인 계층적 구조로 표현 가능.
 - 인공신경망 구조: 뉴런, 계층, 가중치
 - 인공신경망 훈련: 순전파, 역전파, 경사하강법
 - 인공신경망 파라미터: 계층, 노드 수, 활성화함수, 손실함수, 학습률
### 3.1. 구조, 훈련, 하이퍼파라미터
  - 뉴런은 층을 이루며 복잡하게 배열됨.
  - 모델을 거쳐 얻은 결과와 에상치를 비교하는 방식으로 훈련 단계를 진행.
  - 이를 통해 데이터 내의 패턴을 인식하는 방법을 학습한다.
   - 뉴런(=인공 뉴런, 노드, 퍼셉트론)
    - 하나 이상의 입력과 출력은 단 하나.
     - 뉴런에 있는 활성화 함수가 여러 입력과 하나의 출력 간 복잡한 비선형적 함수의 매핑을 결정한다.
     - 입력(x_1, ..., x_n)을 받아서 훈련 매개변수 적용해 가중치 합(z) 생성한 후 활성화함수(f)에 전달하여 출력 계산f(z).
     - 하나의 뉴런에서 나온 출력만으로는 복잡한 계산 불가능.
     - 수직, 수평적으로 뉴런을 쌓아간다.
     - 입력층으로 입력이 오면, 입력에 직접 노출되지 않는 은닉층으로. 가장 단순한 신경망 구조는 은닉층에 뉴런이 하나 있는 형태.
     - 세 개 이상 많은 은닉층을 가지면 심층 신경망DNN이라고 한다. 더 많은 연산이 필요하다.
     - 출력층은 한 개의 값이나 벡터값을 출력함.
   - 뉴런 가중치
      - 단위 간 연결 강도를 나타냄. 입력이 출력에 미치는 영향을 수치화.
      - 가중치 0은 입력의 변화가 출력에 영향 없는 상태, 음의 가중치는 입력 증가가 출력에는 감소를 의미.
 - 훈련
  - 훈련이란 모든 가중치를 적합하게 조정해나가는 것. 순전파와 역전파 단계를 반복.
  - 순전파
   - 입력값 받고 예측값이라는 출력을 얻는 과정. 입력 받을 때는 어떠한 연산도 없음.
   - 다음 층에서는 입력값에 곱셈, 덧셈, 활성화 연산을 하고 결과를 다음 층에 전달.
   - 순차적으로 진행 후 마지막 충에서 출력값 도출.
  - 역전파
   - 예측값과 기댓값의 차이를 손실함수(비용함수) J(w)로 변환. w는 가중치.
   - 목표는 훈련셋을 가지고 손실함수를 최적화하는 것. 즉, 손실을 가능한 최소화하는 것.
   - 이 때 사용하는 방법이 경사하강법. 경사가 낮아지는 방향으로 이동하여 가장 낮은 값이 될 때까지.
   - J(w)의 경사를 찾아야 한다. p q r을 각각의 층이라 하면 J(w)=r(q(p()))이다.
   - 첫 층의 가중치의 경사는 두, 세번째 경사에 의존. 두 번째 층의 경사는 세번째 층 가중치의 경사에 의존함.
   - 마지막인 세번째 층부터 역방향 미분을 적용해 나간다. 따라서 역전파이다.
   - 모델 오차를 망을 통해 한 번에 하나의 층으로 전파해 나가며 오차만큼 가중치를 튜닝해나간다.
   - 역전파는 경사를 찾는 가장 명확하고 효율적인 방법이다.
  - 하이퍼파라미터
    - 훈련 이전 정하는 변수라 훈련 중에 바뀌지 않는 변수.
    - 하이퍼파라미터를 통해 신경망을 유연하게 하지만, 이 유연성 때문에 모델 튜닝이 어려워짐.
  - 은닉층 및 노드의 수
   - 은닉층과 노드가 많아지면 매개변수도 많아지고, 모델은 복잡한 함수 구현에 적합해짐.
   - 잘 일반화할 수 있는 훈련된 망 가지려면 은닉층과 은닉층 노드 개수 최적화가 필요.
   - 층 수가 적으면 시스템 오차 증가, 층 수가 많으면 과적합. 그러나 결정하는 확실한 방법은 없다.

     - 대규모 이미지, 음성 인식 같은 복잡한 작업은 수십개 층과 엄청 많은 훈련 데이터 필요.
     - 대부분의 문제에서는 한두개 은닉층으로 시작해서 과적합될 때까지 층의 개수 늘려나감.
     - 숨겨진 노드 수는 입출력 노드 수, 훈련 데이터 양, 모델에서의 함수 복잡도와 관련.
     - 경험적으로, 각 층 숨겨진 노드는 입출력 크기 사이의 중간값으로 정하면 됨.
     - 숨겨진 노드는 과적합 방지를 위해 입력 노드 2배를 넘기면 안 됨.
   - 학습률
     - 가중치 최적화를 위해 순전파, 역전파를 반복한다.
     - 반복마다 각 가중치에 대한 손실함수 미분을 계산하고, 미분값을 가중치에서 뺀다.
     - 얼마나 빠르게/느리게 가중치 값을 변하게 할지는 학습률이 ㄱ려정.
     - 적당한 시간 안에 수렴할 만큼 학습률은 커야 하고, 손실함수 최솟값을 찾을만큼 작아야 한다.
   - 활성화 함수
        - 기대하는 출력을 얻기 위해 입력 가중치 합을 받는 함수이다.
        - 활성화함수를 이용해 신경망은 더 복잡한 방법으로 입력 결합 가능.
        - 또한 신경망 모델과 그 출력의 관계를 더 잘 표현 가능. 어떤 뉴런을 활성화할지, 즉 어떤 정보를 다음 층에 전달할지 결정한다.
        - 활성화함수가 없다면 인공신경망은 큰 학습 능력을 잃게 된다.
            - 선형함수(항등함수)
                - 직선 방정식(f(x)=mx + c)로 나타내고 활성은 입력에 비례한다.
                - 여러 층이 있고 모두 선형적이면, 마지막 층 활성화함수는 첫 번째 층 선형 함수와 같다.
                - 선형 함수 범위는 -inf에서 +inf.
            - 시그모이드 함수
                - S자 형의 함수. 출력 범위는 0~1. 논리 활성화함수 라고도 한다.
                - f(x) = 1 / (1 + e^-x)
            - 하이퍼볼릭 탄젠트 함수(Tanh)
                - Tanh(x) = 2Sigmoid(2x) - 1
                - -1~+1까지의 출력 범위.
            - 렐루 함수 ReLU: 정류선형유닛 Rectified Linear Unit의 줄임말
                - f(x) = max(x, 0)
                - 양수면 입력값을 그대로 전달, 음수면 0을 전달. 함수의 단순성 때문에 많이 활용.
        - 활성화함수를 고르는 방법은 없다.
        - 단지 문제 속성과 모델로 표현되는 관계에 의존할 뿐.
        - 여러 다른 활성화 함수를 적용해보고 더 빨리 수렴하고 효율적 훈련을 보여주는 함수로 선택할 수도 있다.
        - 출력층에서의 활성화함수는 대부분 모델로 표현되는 문제 유형으로 결정됨.
    - 비용 함수(손실 함수)
        - 인공신경망 성능의 정도와 얼마나 실험 데이터에 적합한지를 측정한다.
            - 평균 제곱 오차 MSE
                - 회귀형 문제에 우선적으로 적용. 연속값을 출력한다.
                - 예측과 실제 차이에 제곱하여 평균 낸 것.
            - 교차 엔트로피 (로그 손실)
                - 분류형 문제에 우선적으로 적용.
                - 0~1 사이의 확률값을 출력된다.
                - 예측되는 확률이 실제 분류에서 멀어지면 교차 엔트로피 손실이 커진다. 완벽한 모델은 0의 교차 엔트로피를 갖는 것.
    - 최적화 알고리즘
        - ㅗㅗ
    - 에폭
    - 배치 크기
           


     


### 3.2. 인공신경망 모델 생성
## 4장. 지도학습: 모델 및 개념


















